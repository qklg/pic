---
title: '拿vps跑deepseek r1'
date: 2025-01-29 17:27:13
tags: []
published: true
hideInList: false
feature: 
isTop: false
---
# 前言

前排提示:ollama很吃性能的，别拿你的生产力的小鸡跑
建议内存大点的鸡上跑



# 1 docker安装openwebui+ollama

https://github.com/open-webui/open-webui
For CPU Only: If you're not using a GPU, use this command instead:

```
docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
```

# 2 访问及设置

## ① 访问

 ip:3000端口打开即可，有条件的话nginx反代下

## ② 设置用户名密码邮箱



 ![image-20250129170712679](https://s3.qklg.net/img/YYnrsjR.png)

##③ 切换语言

点击右上角头像下面的settings-general，选择中文，save保存

![image-20250129170809543](https://s3.qklg.net/img/0GbOotp.png)



![image-20250129170824068](https://s3.qklg.net/img/0fPh5qs.png)

## ④ 添加模型

左上角选择一个模型的话可以输入你想要的模型，

我们选择7b的，输入 deepseek-r1:7b,从ollama拉取

![image-20250129171023372](https://s3.qklg.net/img/nOPOWHY.png)

下载deepseek的7b模型，小鸡的性能跑个7b还是可以的
如果没法跑的话，可以跑1.5b的  deepseek-r1:1.5b

其他的模型的话这边
https://ollama.com/library/deepseek-r1

# 3 闲言碎语

本人用签名探针上的家里云。配置为5600+32G内存跑的

占用的话大概cpu在50%左右，内存吃到10G
我的cpu的话跑分gb5单核1675多，多核8934，你可以参考下自己跑着玩

![image-20241110200910735](https://s3.qklg.net/img/cpzRGgs.png)

7.5b的效果其实不怎么样，你们跑了就知道了

![](https://s3.qklg.net/img/IsaW10B.png)

其实还不如自己直接调用api来的合适

跑api的话可以参考我这个帖子

https://qklg.net/post/20250127/

有条件上显卡跑，而且显存至少16G的，这种纯cpu跑的是玩具
隔壁老哥拿12400跑72b的https://linux.do/t/topic/397701/20
半小时才能回答一次，隔壁老哥cpu当一回时代先锋